# Rapport d'Apprentissage Python - Brief Pipeline d'Analyse de Logs SSH

**Analyste** : Yassine Bouzidi  
**Formation** : Simplon - Administrateur Solutions Cybers√©curit√©  
**Date** : 21/22 Novembre 2025  
**Dur√©e du brief** : 3 phases (ETL, Jupyter, Visualisation)

---

## üìö Contexte du Projet

Dans le cadre de ma formation en cybers√©curit√©, j'ai d√©velopp√© un pipeline complet d'analyse de logs SSH pour d√©tecter et visualiser des attaques par force brute sur un serveur critique. Ce projet m'a permis d'acqu√©rir des comp√©tences en Python pour le traitement de donn√©es et la cr√©ation de rapports SOC.

---

## üéØ Objectifs d'Apprentissage

L'objectif principal √©tait de ma√Ætriser la cha√Æne de traitement de la donn√©e de s√©curit√© : **Collecte ‚Üí Parsing ‚Üí Normalisation ‚Üí Analyse ‚Üí Reporting**.

### Comp√©tences Techniques Vis√©es
1. Manipulation de fichiers texte et CSV en Python
2. Utilisation des expressions r√©guli√®res (regex) pour le parsing
3. Analyse de donn√©es avec Pandas
4. Cr√©ation de visualisations avec Matplotlib/Seaborn
5. Utilisation de Jupyter Notebook pour la pr√©sentation d'analyses

### Comp√©tences SOC
1. Identification de patterns d'attaques SSH
2. Analyse de logs de s√©curit√©
3. Cr√©ation de rapports d'incident
4. Formulation de recommandations de durcissement

---

## üöÄ Fonctionnalit√©s Cl√©s

- **Parsing Avanc√©** : Analyse de 55 types d'√©v√©nements SSH diff√©rents (authentification, erreurs r√©seau, tentatives d'intrusion).
- **Gestion Intelligente des Dates** : D√©tection automatique des changements d'ann√©e (ex: passage de d√©c. 2024 √† janv. 2025) pour une chronologie exacte, m√™me sur des logs √† cheval sur deux ann√©es.
- **Z√©ro Faux N√©gatifs** : Syst√®me d'identification exhaustif atteignant **0% de logs "UNKNOWN"** gr√¢ce √† un moteur d'expressions r√©guli√®res (Regex) it√©ratif et optimis√©.
- **D√©tection des Menaces** : Identification pr√©cise des attaques par force brute, des utilisateurs invalides et des anomalies de protocole (ex: *Bad packet length*, *Corrupted MAC*).
- **Rapports Automatis√©s** : G√©n√©ration de rapports CSV d√©taill√©s pour l'analyse approfondie et d'un r√©sum√© ex√©cutif affich√© en console avec les statistiques cl√©s (Top attaquants, volum√©trie).

---

## üìñ Apprentissages Python par Phase

### Phase 1 : ETL et Scripting Python

#### Concepts Appris
**1. Manipulation de Fichiers**
Lecture de fichiers ligne par ligne:

with open('SSH.txt', 'r', encoding='utf-8') as f:
for line in f:


# Traitement
**Apprentissage** : J'ai d√©couvert l'importance du gestionnaire de contexte `with` pour g√©rer automatiquement la fermeture des fichiers et √©viter les fuites m√©moire.

**2. Expressions R√©guli√®res (Regex)**
import re
ip_pattern = r'from\s+(\d{1,3}.\d{1,3}.\d{1,3}.\d{1,3})'
match = re.search(ip_pattern, message)

**Apprentissage** : Les regex sont puissantes pour extraire des patterns dans du texte non structur√©. J'ai appris :
- Les groupes de capture `( )`
- Les quantificateurs `+`, `*`, `{n,m}`
- Les raw strings `r''` pour √©viter l'√©chappement excessif
- La diff√©rence entre `.search()` et `.match()`

**3. Structures de Donn√©es**
Dictionnaires pour organiser les donn√©es
event_patterns = {
'E9': r'Failed password for (?!invalid user).+',
'E10': r'Failed password for invalid user .+'
}

**Apprentissage** : Les dictionnaires Python sont id√©aux pour mapper des cl√©s (EventId) √† des valeurs (patterns regex). J'ai compris l'importance de structurer les donn√©es d√®s la conception.

**4. Module CSV**
import csv
with open('output.csv', 'w', newline='', encoding='utf-8') as f:
writer = csv.DictWriter(f, fieldnames=['Timestamp', 'EventId'])
writer.writeheader()
writer.writerows(results)

**Apprentissage** : Le param√®tre `newline=''` est crucial sous Windows pour √©viter les lignes vides. J'ai appris la diff√©rence entre `csv.writer` et `csv.DictWriter`.

**5. Gestion des Dates**
from datetime import datetime
timestamp = datetime.strptime('Dec 10 06:55:46 2025', '%b %d %H:%M:%S %Y')

**Apprentissage** : Les formats de date peuvent √™tre complexes. J'ai d√©couvert les directives `strptime` (%b, %d, %H, etc.) pour parser des dates en diff√©rents formats.

#### Difficult√©s Rencontr√©es

**Probl√®me 1 : FileNotFoundError**
- **Erreur** : Le script ne trouvait pas `SSH.txt` malgr√© sa pr√©sence
- **Cause** : Diff√©rence entre le r√©pertoire de travail et l'emplacement du fichier
- **Solution** : Utilisation de `os.path.dirname(__file__)` pour des chemins relatifs robustes

**Probl√®me 2 : SyntaxError avec raw strings**
- **Erreur** : `unterminated string literal` avec les chemins Windows
- **Cause** : Raw strings ne peuvent pas se terminer par un backslash seul
- **Solution** : Utilisation de slashes `/` ou double backslash `\\`

**Probl√®me 3 : Patterns Regex trop g√©n√©riques**
- **Erreur** : EventId E9 capturait aussi E10
- **Cause** : Regex mal ordonn√©es et patterns qui se chevauchent
- **Solution** : Ordre de priorit√© explicite et negative lookahead `(?!invalid user)`

**Probl√®me 4 : Persistance de logs "UNKNOWN"**
- **Erreur** : 1957 lignes (0.3%) class√©es comme inconnues, masquant potentiellement des attaques.
- **Cause** : Patterns regex trop stricts (ex: espaces manquants) et √©v√©nements non pr√©vus (erreurs Java/JCraft, probl√®mes de protocole).
- **Solution** : 
  1. Analyse it√©rative des messages rejet√©s.
  2. Cr√©ation de 20 nouveaux patterns (E28-E55).
  3. Flexibilisation des regex avec `\s+`.
  4. R√©sultat : **0 log inconnu (100% de couverture)**.

---

### Phase 2 : Jupyter Notebook et Environnement de Travail

#### Concepts Appris

**1. Installation de Packages**
python -m pip install pandas matplotlib seaborn jupyter


**Apprentissage** : J'ai compris la diff√©rence entre `pip install` et `python -m pip install` (plus fiable pour garantir l'installation dans le bon environnement Python).

**2. Cellules Markdown vs Code**

**Apprentissage** : Jupyter permet d'alterner entre :
- **Cellules Markdown** : Documentation, titres, explications (storytelling)
- **Cellules Code** : Ex√©cution de Python avec r√©sultats affich√©s

Cette s√©paration est id√©ale pour cr√©er des rapports SOC lisibles et reproductibles.

**3. Kernels et Environnements**

**Apprentissage** : VS Code peut avoir plusieurs environnements Python. J'ai appris √† :
- V√©rifier le kernel actif en haut √† droite du notebook
- Installer les packages dans le bon environnement
- Utiliser `!pip install` directement dans une cellule Jupyter

#### Difficult√©s Rencontr√©es

**Probl√®me 1 : ModuleNotFoundError pour pandas**
- **Erreur** : `No module named 'pandas'`
- **Cause** : Packages install√©s dans un environnement Python diff√©rent du kernel Jupyter
- **Solution** : Installation dans le kernel actif ou s√©lection du bon kernel

**Probl√®me 2 : Cellule Markdown interpr√©t√©e comme Code**
- **Erreur** : `SyntaxError: invalid syntax` sur du texte Markdown
- **Cause** : Type de cellule incorrect (Python au lieu de Markdown)
- **Solution** : Conversion en Markdown avec le menu d√©roulant ou raccourci `M`

---

### Phase 3 : Analyse de Donn√©es avec Pandas et Visualisation

#### Concepts Appris

**1. DataFrames Pandas**
df = pd.read_csv('datasetssh.csv')
df.head() # Aper√ßu
df.shape # Dimensions
df.info() # Types de colonnes

**Apprentissage** : Les DataFrames sont comme des tableaux Excel en Python. J'ai d√©couvert des m√©thodes puissantes pour explorer rapidement les donn√©es.

**2. Conversion de Types**
df['Timestamp'] = pd.to_datetime(df['Timestamp'])
df['Hour'] = df['Timestamp'].dt.hour

**Apprentissage** : Pandas g√®re automatiquement les dates avec `.dt` accessor. Cela simplifie √©norm√©ment l'analyse temporelle.

**3. Agr√©gations et Comptages**
top_ips = df['SourceIP'].value_counts().head(5)
root_attacks = df[df['User'] == 'root'].shape

**Apprentissage** : `.value_counts()` est incroyablement utile pour compter les occurrences. Le filtrage avec `df[condition]` est intuitif.

**4. Visualisations avec Matplotlib**
plt.figure(figsize=(14, 6))
plt.bar(x, y, color='crimson')
plt.xlabel('Label')
plt.title('Titre')
plt.show()

**Apprentissage** : Matplotlib suit une logique de "peinture" successive. J'ai appris √† :
- D√©finir la taille avec `figsize`
- Personnaliser les couleurs et styles
- Ajouter des labels et titres
- Afficher avec `.show()`

**5. Pie Charts**
plt.pie(values, labels=labels, autopct='%1.1f%%', startangle=90)

**Apprentissage** : Les pie charts sont efficaces pour montrer des proportions. Le param√®tre `autopct` affiche automatiquement les pourcentages.

#### Difficult√©s Rencontr√©es

**Probl√®me 1 : Valeurs NaN dans les colonnes**
- **Erreur** : Certaines IPs ou utilisateurs √©taient `NaN`
- **Cause** : Regex ne captaient pas tous les formats de logs
- **Solution** : Patterns regex am√©lior√©s et gestion des cas manquants

**Probl√®me 2 : Graphiques pas affich√©s dans Jupyter**
- **Erreur** : Code ex√©cut√© mais pas de graphique visible
- **Cause** : Oubli de `plt.show()` ou mauvaise configuration du backend
- **Solution** : Ajout syst√©matique de `.show()` et configuration inline

---

## üõ†Ô∏è Ressources Utilis√©es

### Documentation Officielle
1. **Python Docs** : https://docs.python.org/3/
   - Module `re` (regex)
   - Module `csv`
   - Module `datetime`

2. **Pandas Documentation** : https://pandas.pydata.org/docs/
   - Getting Started Guide
   - API Reference pour DataFrame
   - Time Series / Date functionality

3. **Matplotlib Documentation** : https://matplotlib.org/stable/
   - Pyplot Tutorial
   - Gallery d'exemples

4. **Jupyter Documentation** : https://jupyter-notebook.readthedocs.io/
   - Installation guide
   - Markdown cells

### Tutoriels et Articles
1. **Real Python** : Tutoriels sur regex, pandas, et matplotlib
2. **Stack Overflow** : R√©solution de probl√®mes sp√©cifiques (FileNotFoundError, SyntaxError)
3. **GeeksforGeeks** : Exemples de code pour value_counts(), to_datetime()

### Outils de D√©veloppement
1. **VS Code** : √âditeur avec extension Jupyter
2. **PowerShell** : Terminal pour ex√©cution des scripts
3. **Git** : Versioning du code (recommand√© pour la suite)

---

## üí° Comp√©tences Acquises

### Comp√©tences Techniques Python

| Comp√©tence |
|------------|
| Manipulation de fichiers | 
| Expressions r√©guli√®res |
| Pandas DataFrames |
| Visualisation (Matplotlib) |
| Jupyter Notebook |

### Comp√©tences SOC

- **Analyse de logs** : Capacit√© √† parser et interpr√©ter des logs SSH
- **D√©tection de menaces** : Identification de patterns d'attaques par force brute
- **Reporting** : Cr√©ation de rapports visuels pour stakeholders
- **Recommandations** : Formulation de mesures de durcissement pertinentes

---

## üîÑ M√©thodologie de Travail

### Approche It√©rative

J'ai adopt√© une approche **it√©rative** pour ce projet :

1. **Version 1** : Script basique qui lit les fichiers
2. **Version 2** : Ajout du parsing regex simple
3. **Version 3** : Am√©lioration des patterns et gestion des erreurs
4. **Version 4** : Optimisation et ajout de statistiques
5. **Version 5** : Int√©gration Jupyter et visualisations

### Debugging M√©thodique

Pour chaque erreur rencontr√©e :
1. **Lecture du message d'erreur** (ligne, type d'erreur)
2. **Isolation du probl√®me** (test sur un √©chantillon r√©duit)
3. **Recherche de solutions** (documentation, Stack Overflow)
4. **Test de la correction**
5. **Documentation de la solution** (commentaires dans le code)

### Test et Validation

- Test sur les **5 premi√®res lignes** avant de traiter l'ensemble
- V√©rification des **outputs interm√©diaires** (print statements)
- Validation des **r√©sultats** avec des calculs manuels sur un √©chantillon

---

## üìà √âvolution et Prochaines √âtapes

### Points Forts du Projet
‚úÖ Pipeline ETL fonctionnel et robuste  
‚úÖ Code bien comment√© et structur√©  
‚úÖ Visualisations claires et pertinentes  
‚úÖ Rapports exploitables pour SOC  

### Axes d'Am√©lioration
üîÑ Ajouter des tests unitaires (pytest)  
üîÑ G√©rer des formats de logs multiples (Apache, Nginx, etc.)  
üîÑ Cr√©er une interface web (Flask/Streamlit)  
üîÑ Automatiser avec des scripts cron  
üîÑ Int√©grer avec des SIEM (Splunk, ELK)  

### Comp√©tences √† Approfondir
üìö Machine Learning pour d√©tection d'anomalies  
üìö API REST pour exposer les r√©sultats  
üìö Docker pour conteneurisation du pipeline  
üìö Bases de donn√©es (PostgreSQL) pour stocker les logs  

---

## üéì Conclusion

Ce brief m'a permis de d√©velopper des comp√©tences solides en Python pour l'analyse de donn√©es de s√©curit√©. J'ai appris √† :

1. **Automatiser** des t√¢ches r√©p√©titives de parsing de logs
2. **Structurer** des donn√©es non structur√©es avec des regex
3. **Analyser** des volumes importants de donn√©es avec Pandas
4. **Communiquer** des r√©sultats techniques via des visualisations
5. **Documenter** mon travail de mani√®re professionnelle

**Python est devenu un outil essentiel dans ma bo√Æte √† outils de cybers√©curit√©.**

---

**Yassine Bouzidi**  
Administrateur Solutions Cybers√©curit√© en Formation  chez Simplon
Novembre 2025

